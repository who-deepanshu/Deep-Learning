
# Natural Language Processing
A machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.

This directory holds NLP methods which are used to pre-Process textual data before passed to NLP model as machine can't understand textual data thus we convert into vector forms.

## Tokenization 
- The process of converting a sequence of text into smaller parts, known as tokens. These tokens can be as small as characters or as long as words.
![token](https://github.com/who-deepanshu/Deep-Learning/assets/129099978/9c026a0a-8b8b-451f-ad32-be342fe40a8c)


## Stopwords
- To eliminate words that are so widely used that they carry very little useful information. 


## Stemming & Lemmatization
- Both aims to reduce inflections down to common base root words.
![stemlemma](https://github.com/who-deepanshu/Deep-Learning/assets/129099978/a88c54f0-9a69-4960-890d-47819b36a076)
