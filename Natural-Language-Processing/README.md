
# Natural Language Processing
A machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.

This directory holds NLP methods which are used to pre-Process textual data before passed to NLP model as machine can't understand textual data thus we convert into vector forms.

## Tokenization 
- The process of converting a sequence of text into smaller parts, known as tokens. These tokens can be as small as characters or as long as words.


## Stopwords
- To eliminate words that are so widely used that they carry very little useful information. 


## Stemming & Lemmatization
- Both aims to reduce inflections down to common base root words.
